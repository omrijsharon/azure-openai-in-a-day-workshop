{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Embeddings for unsupervised clustering with named clusters (and other fun things)\n",
    "\n",
    "In this notebook, we use a subset of the [Top 10000 Popular Movies Dataset](https://www.kaggle.com/datasets/db55ac3dfd0098a0cf96dd542807f9253a16587ff233e06baef372bccfd09942) to calculate embeddings on movie descriptions and then apply kmeans to find similar clusters. Once we have these clusters, we'll use a prompt to extract the topics from each cluster. \n",
    "\n",
    "Fill out the missing pieces in the source source to get everything working (indicated by `#FIXME`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDING_MODEL text-embedding-ada-002\n",
      "EMBEDDING_ENCODING cl100k_base\n",
      "EMBEDDING_CHUNK_SIZE 8000\n",
      "COMPLETION_MODEL gpt-35-turbo\n",
      "OPENAI_API_VERSION 2022-12-01\n",
      "OPENAI_API_BASE https://neuronvisionws1.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Configure Azure OpenAI Service API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = os.getenv('OPENAI_API_VERSION', \"2022-12-01\")\n",
    "OPENAI_API_BASE = openai.api_base = os.getenv('OPENAI_API_BASE')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define embedding model and encoding\n",
    "EMBEDDING_MODEL = os.getenv('OPENAI_EMBEDDING_MODEL', 'text-embedding-ada-002')\n",
    "EMBEDDING_ENCODING = os.getenv('OPENAI_EMBEDDING_ENCODING', 'cl100k_base')\n",
    "EMBEDDING_CHUNK_SIZE = os.getenv('OPENAI_EMBEDDING_CHUNK_SIZE', 8000)\n",
    "COMPLETION_MODEL = os.getenv('OPENAI_COMPLETION_MODEL', 'gpt-35-turbo')\n",
    "\n",
    "# initialize tiktoken for encoding text\n",
    "encoding = tiktoken.get_encoding(EMBEDDING_ENCODING)\n",
    "\n",
    "params_gathered = dict(\n",
    "    EMBEDDING_MODEL=EMBEDDING_MODEL,\n",
    "    EMBEDDING_ENCODING=EMBEDDING_ENCODING,\n",
    "    EMBEDDING_CHUNK_SIZE=EMBEDDING_CHUNK_SIZE,\n",
    "    COMPLETION_MODEL=COMPLETION_MODEL,\n",
    "    OPENAI_API_VERSION=openai.api_version,\n",
    "    OPENAI_API_BASE=OPENAI_API_BASE\n",
    ")\n",
    "for key, val in params_gathered.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `movies.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 381284.0,\n",
       " 'original_language': 'en',\n",
       " 'original_title': 'Hidden Figures',\n",
       " 'popularity': 49.802,\n",
       " 'release_date': '2016-12-10',\n",
       " 'vote_average': 8.1,\n",
       " 'vote_count': 7310.0,\n",
       " 'genre': \"['Drama', 'History']\",\n",
       " 'overview': 'The untold story of Katherine G. Johnson, Dorothy Vaughan and Mary Jackson – brilliant African-American women working at NASA and serving as the brains behind one of the greatest operations in history – the launch of astronaut John Glenn into orbit. The visionary trio crossed all gender and race lines to inspire generations to dream big.',\n",
       " 'revenue': 230698791.0,\n",
       " 'runtime': 127.0,\n",
       " 'tagline': \"Meet the women you don't know, behind the mission you do.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/movies/movies.csv')\n",
    "print(df.shape)\n",
    "dict(df.iloc[0].items())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a new column and calculate how many tokens each embedding would cost. This allows us to get an estimate how much we'd pay to create embeddings on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 381284.0, 'original_language': 'en', 'original_title': 'Hidden Figures', 'popularity': 49.802, 'release_date': '2016-12-10', 'vote_average': 8.1, 'vote_count': 7310.0, 'genre': \"['Drama', 'History']\", 'overview': 'The untold story of Katherine G. Johnson, Dorothy Vaughan and Mary Jackson – brilliant African-American women working at NASA and serving as the brains behind one of the greatest operations in history – the launch of astronaut John Glenn into orbit. The visionary trio crossed all gender and race lines to inspire generations to dream big.', 'revenue': 230698791.0, 'runtime': 127.0, 'tagline': \"Meet the women you don't know, behind the mission you do.\", 'token_count': 62}\n",
      "Test would cost $0.0118184 for embeddings\n"
     ]
    }
   ],
   "source": [
    "# add a new column to the dataframe where you put the token count of the overview\n",
    "def get_num_tokens_from_string(input_text: str, encoding_name: str='p50k_base') -> int:\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    return len(encoding.encode(input_text))\n",
    "\n",
    "df['token_count'] = df['overview'].apply(get_num_tokens_from_string)\n",
    "\n",
    "# print the first 5 rows of the dataframe, then also the total number of tokens\n",
    "print(dict(df.iloc[0].items()))\n",
    "total_tokens = df['token_count'].sum()\n",
    "\n",
    "cost_for_embeddings = total_tokens / 1000 * 0.0004\n",
    "print(f\"Test would cost ${cost_for_embeddings} for embeddings\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our embedding method. Please note the use of tenacity for having an automated retry mechanism, in case we hit the TPS limits of Azure OpenAI Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(10))\n",
    "def get_embedding(text) -> list[float]:\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return model.encode(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's creating the embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>genre</th>\n",
       "      <th>overview</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>tagline</th>\n",
       "      <th>token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>381284.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Hidden Figures</td>\n",
       "      <td>49.802</td>\n",
       "      <td>2016-12-10</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7310.0</td>\n",
       "      <td>['Drama', 'History']</td>\n",
       "      <td>The untold story of Katherine G. Johnson, Doro...</td>\n",
       "      <td>2.306988e+08</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Meet the women you don't know, behind the miss...</td>\n",
       "      <td>62</td>\n",
       "      <td>[-0.04648739, -0.013596974, -0.018194607, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>356334.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Gridlocked</td>\n",
       "      <td>9.801</td>\n",
       "      <td>2016-06-14</td>\n",
       "      <td>5.8</td>\n",
       "      <td>130.0</td>\n",
       "      <td>['Action']</td>\n",
       "      <td>Former SWAT leader David Hendrix and hard-part...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>114.0</td>\n",
       "      <td>Only one way out…</td>\n",
       "      <td>36</td>\n",
       "      <td>[-0.07511196, 0.05680961, -0.032894667, 0.0163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>475557.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Joker</td>\n",
       "      <td>116.462</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>8.2</td>\n",
       "      <td>18970.0</td>\n",
       "      <td>['Crime', 'Thriller', 'Drama']</td>\n",
       "      <td>During the 1980s, a failed stand-up comedian i...</td>\n",
       "      <td>1.074251e+09</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Put on a happy face.</td>\n",
       "      <td>35</td>\n",
       "      <td>[0.06370305, 0.0003377361, -0.057780314, 0.016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347847.0</td>\n",
       "      <td>en</td>\n",
       "      <td>The Sand</td>\n",
       "      <td>14.172</td>\n",
       "      <td>2015-08-28</td>\n",
       "      <td>5.1</td>\n",
       "      <td>157.0</td>\n",
       "      <td>['Horror']</td>\n",
       "      <td>Just when you thought it was safe to go back i...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>This Beach is Killer</td>\n",
       "      <td>132</td>\n",
       "      <td>[0.03406623, 0.0416562, 0.026990961, 0.0238385...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>739542.0</td>\n",
       "      <td>en</td>\n",
       "      <td>America: The Motion Picture</td>\n",
       "      <td>98.542</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>5.8</td>\n",
       "      <td>130.0</td>\n",
       "      <td>['Action', 'Comedy', 'History', 'Animation', '...</td>\n",
       "      <td>A chainsaw-wielding George Washington teams wi...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>98.0</td>\n",
       "      <td>This summer they're redrawing history.</td>\n",
       "      <td>36</td>\n",
       "      <td>[-0.10075497, 0.045750607, -0.0045793317, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id original_language               original_title  popularity  \\\n",
       "0  381284.0                en               Hidden Figures      49.802   \n",
       "1  356334.0                en                   Gridlocked       9.801   \n",
       "2  475557.0                en                        Joker     116.462   \n",
       "3  347847.0                en                     The Sand      14.172   \n",
       "4  739542.0                en  America: The Motion Picture      98.542   \n",
       "\n",
       "  release_date  vote_average  vote_count  \\\n",
       "0   2016-12-10           8.1      7310.0   \n",
       "1   2016-06-14           5.8       130.0   \n",
       "2   2019-10-02           8.2     18970.0   \n",
       "3   2015-08-28           5.1       157.0   \n",
       "4   2021-06-30           5.8       130.0   \n",
       "\n",
       "                                               genre  \\\n",
       "0                               ['Drama', 'History']   \n",
       "1                                         ['Action']   \n",
       "2                     ['Crime', 'Thriller', 'Drama']   \n",
       "3                                         ['Horror']   \n",
       "4  ['Action', 'Comedy', 'History', 'Animation', '...   \n",
       "\n",
       "                                            overview       revenue  runtime  \\\n",
       "0  The untold story of Katherine G. Johnson, Doro...  2.306988e+08    127.0   \n",
       "1  Former SWAT leader David Hendrix and hard-part...  0.000000e+00    114.0   \n",
       "2  During the 1980s, a failed stand-up comedian i...  1.074251e+09    122.0   \n",
       "3  Just when you thought it was safe to go back i...  0.000000e+00     84.0   \n",
       "4  A chainsaw-wielding George Washington teams wi...  0.000000e+00     98.0   \n",
       "\n",
       "                                             tagline  token_count  \\\n",
       "0  Meet the women you don't know, behind the miss...           62   \n",
       "1                                  Only one way out…           36   \n",
       "2                               Put on a happy face.           35   \n",
       "3                               This Beach is Killer          132   \n",
       "4             This summer they're redrawing history.           36   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.04648739, -0.013596974, -0.018194607, 0.09...  \n",
       "1  [-0.07511196, 0.05680961, -0.032894667, 0.0163...  \n",
       "2  [0.06370305, 0.0003377361, -0.057780314, 0.016...  \n",
       "3  [0.03406623, 0.0416562, 0.026990961, 0.0238385...  \n",
       "4  [-0.10075497, 0.045750607, -0.0045793317, -0.0...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add embeddings to the dataframe\n",
    "df['embedding'] = df['overview'].apply(get_embedding)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create clusters on the embeddings using KMeans. In this case, we'll go for 5 clusters, knowing that this might be wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KMeans' object has no attribute 'labels_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/azure-openai-in-a-day-workshop/exercises/05_movie_classification_unsupervised_incl_recommendations_exercise.ipynb Cell 12\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bcurly-bassoon-r4prxgqrwjj2xp96/workspaces/azure-openai-in-a-day-workshop/exercises/05_movie_classification_unsupervised_incl_recommendations_exercise.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m n_clusters \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bcurly-bassoon-r4prxgqrwjj2xp96/workspaces/azure-openai-in-a-day-workshop/exercises/05_movie_classification_unsupervised_incl_recommendations_exercise.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m kmeans \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39mn_clusters, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bcurly-bassoon-r4prxgqrwjj2xp96/workspaces/azure-openai-in-a-day-workshop/exercises/05_movie_classification_unsupervised_incl_recommendations_exercise.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39massign(cluster\u001b[39m=\u001b[39mkmeans\u001b[39m.\u001b[39;49mlabels_)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bcurly-bassoon-r4prxgqrwjj2xp96/workspaces/azure-openai-in-a-day-workshop/exercises/05_movie_classification_unsupervised_incl_recommendations_exercise.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KMeans' object has no attribute 'labels_'"
     ]
    }
   ],
   "source": [
    "# train k-means on df embeddings\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "# df = df.assign(cluster=kmeans.labels_)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a cluster per row, let's use t-SNE to project our embeddings into 2d space and visualize the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 384)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'cluster'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31383/1841760733.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m tsne = TSNE(\n\u001b[1;32m     19\u001b[0m     \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"random\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'cluster'"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=2, perplexity=15, random_state=42, init=\"random\", learning_rate=200\n",
    ")\n",
    "\n",
    "matrix = np.vstack(df.embedding.values)\n",
    "print(matrix.shape)\n",
    "vis_dims2 = tsne.fit_transform(matrix)\n",
    "\n",
    "x = [x for x, y in vis_dims2]\n",
    "y = [y for x, y in vis_dims2]\n",
    "\n",
    "for category, color in enumerate([\"purple\", \"green\", \"red\", \"blue\",\"yellow\", 'black', 'orange', 'brown', 'pink', 'grey']):\n",
    "    xs = np.array(x)[df.cluster == category]\n",
    "    ys = np.array(y)[df.cluster == category]\n",
    "    plt.scatter(xs, ys, color=color, alpha=0.3)\n",
    "\n",
    "    avg_x = xs.mean()\n",
    "    avg_y = ys.mean()\n",
    "\n",
    "    plt.scatter(avg_x, avg_y, marker=\"x\", color=color, s=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh ok, that does not look great, but was somehow expected. We have all kinds of movies and with only 5 clusters, this might not be ideal. However, if you look closely, you can make up some rough shape that resembles a cluster. Also, movies might fall into two or more categories, so it kind of makes sense.\n",
    "\n",
    "Lastly, let's take a few examples from each cluster, send them to Azure OpenAI Service and get the common theses extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2499264042.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[27], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    prompt = #FIXME write a prompt that find common topics in the reviews\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# take 10 movies from each cluster and write a prompt that asks what these have in common\n",
    "# ideally you would use more movies than 10, but this is just a demo\n",
    "for i in range(n_clusters):\n",
    "    reviews = df[df['cluster'] == i]['overview'].sample(10)\n",
    "    reviews = \"\\n\".join(reviews.values.tolist())\n",
    "    \n",
    "    prompt = #FIXME write a prompt that find common topics in the reviews\n",
    "    response = #FIXME\n",
    "    print(f\"Cluster {i} topics: {response}\")\n",
    "    movies = df[df['cluster'] == i]['original_title'].sample(25)\n",
    "    print(f\"Movies from cluster {i}: {', '.join(movies.values.tolist())}\")\n",
    "    print(\"================\")    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look too bad. But again, 10 samples for each class might not be enough, given the low number of clusters. Anyway, looking at the movie titles, some of the topics actually make fairly ok sense."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Using the embeddings to build a simple recommendation system"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we can do is use the embeddings for building a very simple recommendation system. So let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = \"Frozen\"\n",
    "\n",
    "# get embedding for movie\n",
    "e = #FIXME\n",
    "\n",
    "# get cosine similarity between movie and all other movies\n",
    "similarities = #FIXME\n",
    "\n",
    "# get most similar movies\n",
    "movies = #FIXME\n",
    "movies[1:6]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the last one, this actually does not look too bad...probably would have been useful if we added movie categories and age ratings to our recommendations... :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ee1bbf3137c7ea9420c4fd488a55642063e5739fe2a7286130d9ba47405b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
